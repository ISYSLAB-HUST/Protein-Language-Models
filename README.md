# Protein-Language-Models

ç®€ä»‹:...


## News

- ðŸŒŸ [2024/08] ...
- ðŸŒŸ [2024/09] ...

![Protein-Language-Models-Overview](https://github.com/shuxiang111/Protein-Language-Models/blob/c71da17722411fb364288d313198d37384f8049d/figures/overview.png)

This is the overview of our article.


## Contents

- [News](#news)
- [Contents](#contents)
- [Models](#models)
  - [Non\-transformer\-based models](#non-transformer-based-models)
  - [Transformer\-based models](#transformer-based-models)
    - [Encoder\-only models](#encoder-only-models)
    - [Decoder\-only models](#decoder-only-models)
    - [Encoder\-decoder models](#encoder-decoder-models)
- [Datasets](#datasets)
  - [Pre\-training datasets](#pre-training-datasets)
  - [Benchmarks](#benchmarks)
- [Tools](#tools)


## Models

### Non-transformer-based models

Model | Time | #Parameters | Base model | Pretraining Dataset |Open-source
---- | ---- | ---- | ---- | ---- | ---- |
[ProtVec](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141287)|2015.11|-|Skip-gram|UniProtKB/Swiss-Prot|Ã—
[ProtVecX](https://www.nature.com/articles/s41598-019-38746-w)|2019.03|-|ProtVec|UniProtKB/Swiss-Prot|Ã—
Seq2vec|2017.04|-|RNN|-|Ã—
UniRep|2018.01|1.2B|LSTM|UniProt|Ã—
SeqVec|2020.03|-|CNN|UniProt|Ã—
UDSMProt|2022.09|-|GPT|-|Ã—

### Transformer-based models

#### Encoder-only models

Model | Time | #Parameters | Base model | Pretraining Dataset |Open-source
---- | ---- | ---- | ---- | ---- | ---- |
ESM-3|2023.06|98B|-|Uniref90|âˆš
ESM-Fold|2022.11|300M|ESM-2|Uniref50|Ã—
ESM-2|2022.07|8M-15B|RoBERTa|Uniref50,PDB|Ã—
ESM-1b|2020.02|650M|RoBERTa|Uniref50|Ã—
ESM-MSA-1b|2021.02|100M|ESM-1b|Uniref50|Ã—
ESM-1v|2021.02|650M|ESM-1b|Uniref90|Ã—
ESM-GearNet|2023.10|-|ESM-1b,GearNet|-|Ã—
ProtTrans|2021.07|87M-731M|Trans.enc.|Uniref50|Ã—
ProteinBERT|2022.02|16M|BERT|Uniref90|Ã—
LM-GVP|2022.04|-|Trans.enc.|Uniref50|Ã—
PrompProtein|2023.02|650M|RoBERTa|Uniref50,PDB|Ã—
ProtFlash|2023.10|79M/174M|Trans.enc.|Uniref50|Ã—
SaProt|2023.10|650M|BERT|-|Ã—
ProteinNPT|2023.12|-|Trans.enc.|-|Ã—
TAPE-BERT|2020.12|110M|BERT|Uniref50,Pfam|Ã—
DistilleProtBert|2022.12|50M|ProtBert|Uniref50,Pfam|Ã—
ProtBert|2020.12|1.1M/34.5M|BERT|Uniref50|Ã—
BioBert|2019.02|110M|BERT|-|Ã—
Bioseq-Bert|2022.05|110M|BERT|Uniprot|Ã—
AminoBert|2023.03|110M|BERT|UniprotKB,Pfam|Ã—
CLEAN|2024.02|100M|-|UniprotKB,PDB,Pfam|Ã—
SignalP 6.0|2023.10|42M|-|UniprotKB|Ã—
BlueBert|2020.04|110M/345M|BERT|-|Ã—
SS-pLM|2023.08|14.8M|Transformer|Uniref50|Ã—

#### Decoder-only models

Model | Time | #Parameters | Base model | Pretraining Dataset |Open-source
---- | ---- | ---- | ---- | ---- | ---- |
ProGen|2020.03|1.2B|GPT|Uniparc SWISS|Ã—
ProtGPT2|2021.01|738M|GPT|Uniref50|Ã—
ZymCTRL|2022.01|738M|GPT|BRENDA|Ã—
RITA|2022.05|1.2B|GPT|Uniref10|Ã—
IgLM|2022.12|13M|GPT|-|Ã—
LM-Design|2023.02|664M|GPT|-|Ã—
ProGen2|2023.10|151M-6.4B|GPT|Uniref90,BFD30,PDB|Ã—
PoET|2023.11|201M|GPT|-|Ã—

#### Encoder-decoder models

Model | Time | #Parameters | Base model | Pretraining Dataset |Open-source
---- | ---- | ---- | ---- | ---- | ---- |
Fold2Seq|2021.01|-|Transformer|-|Ã—
MSA-to-proteion transformer|2022.04|-|Transformer|-|Ã—
MSA-Transformer|2021.07|110M|Transformer|Uniref50|Ã—
ProstT5|2023.07|3B|T5|PDB|Ã—
xTrimoPGLM|2023.07|100B|GLM|Uniref90,ColdFoldDB|Ã—
pAbT5|2023.10|-|T5|-|Ã—
Prot-T5|2022.06|30B|T5|Uniref50|Ã—
AlphaFold2|2020.11|-|Transformer|Uniref30,Uniref90,PDB,BFD|Ã—
AlphaFold3|2024.05|-|-|-|Ã—
OntoProtein|2022.06|-|Transformer|ProteinKG25|Ã—
Mansoor et al.|2021.09|100M|Transformer|-|Ã—

## Datasets

### Pre-training datasets

Dataset | Time | Scale | Link
---- | ---- | ---- | ----
UniProtKB/Swiss-Prot|2023.11|570K|âˆš
UniProtKB/TrEMBL|2023.11|251M|âˆš
UniRef100|2023.11|251M|âˆš
UniRef90|2023.11|314M|âˆš
UniRef50|2023.11|632M|âˆš
UniParc|2023.11|314M|âˆš
UniClust30|-|-|âˆš
Pfam|2023.09|47M|âˆš
BFD|2021.07|2.5B|âˆš
PDB|2023.12|214K|âˆš
AlphafoldDB|2021.11|200M|âˆš
BRENDA|-|-|âˆš
MGnify|-|-|âˆš

### Benchmarks

Dataset | Time | Scale | Link
---- | ---- | ---- | ----
TAPE|2021.09|120K|âˆš
ProteinGym|2022.12|300K|âˆš
CASP|2022.01|-|âˆš
SCOP|2023.01|914K|âˆš
CATH|2023.02|151M|âˆš
EC|2023.11|2.6M|âˆš
GO|2023.11|1.5M|âˆš
CAMEO|-|-|âˆš
Flip|2022.01|320K|âˆš
PEER|2022.11|390K|âˆš

## Tools

Tool | Link
---- | ----
MMseq2|[âˆš](https://github.com/soedinglab/mmseqs2)
HHblits&HHfilter|[âˆš](https://github.com/soedinglab/hh-suite)
Umap&t-SNE|[Umap](https://umap-learn.readthedocs.io/en/latest/)&[t-SNE](https://scikit-learn.org/0.18/preface.html)
PyMOL|[âˆš](https://www.pymol.org/)
TM-align|[âˆš](https://zhanggroup.org/TM-align/)
BLAST|[âˆš](https://blast.ncbi.nlm.nih.gov/Blast.cgi)
Foldseek|[âˆš](https://search.foldseek.com/search)









